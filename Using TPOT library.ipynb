{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f068400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.11.7-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (0.24.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (4.59.0)\n",
      "Collecting xgboost>=1.1.0Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading xgboost-1.5.0-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (1.0.1)\n",
      "Collecting update-checker>=0.16\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting deap>=1.2\n",
      "  Downloading deap-1.3.1-cp38-cp38-win_amd64.whl (108 kB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (1.2.4)\n",
      "Collecting stopit>=1.1.1\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tpot) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tpot) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.12.5)\n",
      "Building wheels for collected packages: stopit\n",
      "  Building wheel for stopit (setup.py): started\n",
      "  Building wheel for stopit (setup.py): finished with status 'done'\n",
      "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11955 sha256=b2b8b9c05e94d8543d891267f5996041707701e18dc74aad7b23bcc9e9e5085e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\a8\\bb\\8f\\6b9328d23c2dcedbfeb8498b9f650d55d463089e3b8fc0bfb2\n",
      "Successfully built stopit\n",
      "Installing collected packages: xgboost, update-checker, stopit, deap, tpot\n",
      "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.7 update-checker-0.18.0 xgboost-1.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecde0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a73efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a515d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf89398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets = np.array(train_labels).reshape((-1,))\n",
    "testing_targets = np.array(test_labels).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99567178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tpot object with a few parameters\n",
    "tpot = TPOTRegressor(scoring = 'neg_mean_absolute_error', \n",
    "                    max_time_mins = 480, \n",
    "                    n_jobs = -1,\n",
    "                    verbosity = 2,\n",
    "                    cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9812415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab7f8c448c54c3f8a2cc2c2f71c4dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.44 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: SGDRegressor(input_matrix, alpha=0.0, eta0=1.0, fit_intercept=False, l1_ratio=1.0, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet, power_t=50.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(max_time_mins=4, n_jobs=-1, scoring='neg_mean_absolute_error',\n",
       "              verbosity=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b816d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sgdregressor',\n",
      "                 SGDRegressor(alpha=0.0, eta0=1.0, fit_intercept=False,\n",
      "                              l1_ratio=1.0, loss='epsilon_insensitive',\n",
      "                              penalty='elasticnet', power_t=50.0))])\n"
     ]
    }
   ],
   "source": [
    "# Show the final model\n",
    "print(tpot.fitted_pipeline_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline as a python script file\n",
    "tpot.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df26ae",
   "metadata": {},
   "source": [
    "para cuando lo probemos en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b916f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file management\n",
    "from google.colab import file\n",
    "\n",
    "# Download the pipeline for local use\n",
    "files.download('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c711c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto imprime los piplines pero cuidado, va a haber muchos\n",
    "# To examine all fitted models\n",
    "# tpot.evaluated_individuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model\n",
    "print(tpot.score(testing_features, testing_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff0ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports that the final pipeline needs\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "# Preprocessing steps\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(training_features)\n",
    "training_features = imputer.transform(training_features)\n",
    "testing_features = imputer.transform(testing_features)\n",
    "\n",
    "# Final pipeline from TPOT\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    GradientBoostingRegressor(alpha=0.95, learning_rate=0.1, loss=\"lad\", \n",
    "                              max_depth=7, max_features=0.75, \n",
    "                              min_samples_leaf=3, min_samples_split=18, \n",
    "                              n_estimators=100, subsample=0.60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81dec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the training data\n",
    "exported_pipeline.fit(training_features, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print('Mean Absolute Error = %0.4f' % np.mean(abs(predictions - testing_targets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
